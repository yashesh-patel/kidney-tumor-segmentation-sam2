{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10713346,"sourceType":"datasetVersion","datasetId":6620884}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/segment-anything-2 /kaggle/working/segment-anything-2\n%cd /kaggle/working/segment-anything-2\n!pip install -q -e .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:45:42.83833Z","iopub.execute_input":"2025-04-18T15:45:42.838845Z","iopub.status.idle":"2025-04-18T15:48:57.966024Z","shell.execute_reply.started":"2025-04-18T15:45:42.838794Z","shell.execute_reply":"2025-04-18T15:48:57.965066Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"###  **To Download all the checkpoints** ","metadata":{}},{"cell_type":"code","source":"# !wget -O /kaggle/working/segment-anything-2/sam2_hiera_tiny.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\"\n# !wget -O /kaggle/working/segment-anything-2/sam2_hiera_small.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt\"\n# !wget -O /kaggle/working/segment-anything-2/sam2_hiera_base_plus.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\"\n# !wget -O /kaggle/working/segment-anything-2/sam2_hiera_large.pt \"https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport cv2\nimport torch\nimport torch.nn.utils\nimport torch.nn.functional as F\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom sklearn.model_selection import train_test_split\n\nfrom sam2.build_sam import build_sam2\nfrom sam2.sam2_image_predictor import SAM2ImagePredictor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:55:47.537332Z","iopub.execute_input":"2025-04-18T15:55:47.537818Z","iopub.status.idle":"2025-04-18T15:55:47.543576Z","shell.execute_reply.started":"2025-04-18T15:55:47.537784Z","shell.execute_reply":"2025-04-18T15:55:47.54253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def set_seeds():\n    SEED_VALUE = 42\n    random.seed(SEED_VALUE)\n    np.random.seed(SEED_VALUE)\n    torch.manual_seed(SEED_VALUE)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(SEED_VALUE)\n        torch.cuda.manual_seed_all(SEED_VALUE)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nset_seeds()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:55:49.488817Z","iopub.execute_input":"2025-04-18T15:55:49.489121Z","iopub.status.idle":"2025-04-18T15:55:49.496063Z","shell.execute_reply.started":"2025-04-18T15:55:49.489098Z","shell.execute_reply":"2025-04-18T15:55:49.495177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Run this for Non-Augmented Data**","metadata":{}},{"cell_type":"code","source":"import os\nfrom sklearn.model_selection import train_test_split\n\n# Dataset directories\nDATASET_PATH = \"/kaggle/input/sample/NOT-AUGMENTED/DATASET_FINAL\"\nimages_dir = os.path.join(DATASET_PATH, \"JPEGImages\")\nmasks_dir = os.path.join(DATASET_PATH, \"Annotations\")\n\n\n# List all image and mask files\nimage_files = sorted([f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\nmask_files = sorted([f for f in os.listdir(masks_dir) if f.endswith('.png')])\n\n# Extract base names (without extensions) for matching\nimage_basenames = {os.path.splitext(f)[0]: f for f in image_files}\nmask_basenames = {os.path.splitext(f)[0]: f for f in mask_files}\n\n# Match images with corresponding masks\ndata = []\nfor base_name in image_basenames:\n    mask_name = base_name + '_mask'  # Add '_mask' to match the mask file\n    if mask_name in mask_basenames:\n        data.append({\n            \"image\": os.path.join(images_dir, image_basenames[base_name]),\n            \"annotation\": os.path.join(masks_dir, mask_basenames[mask_name])\n        })\n    else:\n        print(f\"No matching mask for {image_basenames[base_name]}\")\n\n\n# Check if matching worked\nprint(f\"Total Pairs Found: {len(data)}\")\n\n# Split into train and test sets (80% train, 20% test)\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Display sample data\nprint(f\"Training Samples: {len(train_data)}\")\nprint(f\"Testing Samples: {len(test_data)}\")\n\nsampled_train_data = random.sample(train_data, max(1, int(0.2 * len(train_data))))\nsampled_test_data = random.sample(test_data, max(1, int(0.2 * len(test_data))))\n\n# Combine into one sample list\ndata_sample = sampled_train_data + sampled_test_data\n\nprint(f\"Total Combined Sample Size: {len(data_sample)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:55:52.63459Z","iopub.execute_input":"2025-04-18T15:55:52.63486Z","iopub.status.idle":"2025-04-18T15:55:52.818378Z","shell.execute_reply.started":"2025-04-18T15:55:52.63484Z","shell.execute_reply":"2025-04-18T15:55:52.817633Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Run this for Augmented Data**","metadata":{}},{"cell_type":"code","source":"# import os\n# import re\n# from sklearn.model_selection import train_test_split\n\n# # Dataset directories\n# DATASET_PATH = \"/kaggle/input/sample/AUGMENTED/DATASET_FINAL\"\n# images_dir = os.path.join(DATASET_PATH, \"JPEGImages\")\n# masks_dir = os.path.join(DATASET_PATH, \"Annotations\")\n\n# # List all image and mask files\n# image_files = sorted([f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n# mask_files = sorted([f for f in os.listdir(masks_dir) if f.endswith('.png')])\n\n# # Function to extract base names for matching (keeping augmentation number)\n# def extract_base_name(filename, is_mask=False):\n#     \"\"\"\n#     Extracts base name while preserving augmentation numbers (_augX).\n#     Ensures correct matching of original and augmented files.\n#     \"\"\"\n#     filename = filename.replace(\".jpg\", \"\").replace(\".png\", \"\").replace(\".jpeg\", \"\")\n\n#     if is_mask:\n#         filename = filename.replace(\"_orig_mask\", \"_orig\")  # Convert _orig_mask to _orig for matching\n#         filename = re.sub(r\"_aug_mask(\\d+)\", r\"_aug\\1\", filename)  # Convert _aug_maskX to _augX\n#     else:\n#         filename = filename  # No extra processing needed\n\n#     return filename\n\n# # Create dictionaries mapping base names to file paths\n# image_basenames = {extract_base_name(f): f for f in image_files}\n# mask_basenames = {extract_base_name(f, is_mask=True): f for f in mask_files}\n\n# # Debug: Show extracted base names\n# print(\"Sample extracted image base names:\", list(image_basenames.keys())[:5])\n# print(\"Sample extracted mask base names:\", list(mask_basenames.keys())[:5])\n\n# # Match images with corresponding masks\n# data = []\n# for base in image_basenames:\n#     if base in mask_basenames:\n#         data.append({\n#             \"image\": os.path.join(images_dir, image_basenames[base]),\n#             \"annotation\": os.path.join(masks_dir, mask_basenames[base])\n#         })\n\n# print(f\"Total Pairs Found: {len(data)}\")\n\n# if len(data) == 0:\n#     raise ValueError(\"No matching image-mask pairs found. Please check the filenames and directory structure.\")\n\n# # Split into train and test sets (80% train, 20% test)\n# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# print(f\"Training Samples: {len(train_data)}\")\n# print(f\"Testing Samples: {len(test_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T00:28:19.658231Z","iopub.execute_input":"2025-02-18T00:28:19.658564Z","iopub.status.idle":"2025-02-18T00:28:21.886551Z","shell.execute_reply.started":"2025-02-18T00:28:19.658542Z","shell.execute_reply":"2025-02-18T00:28:21.885841Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Fine Tuning**","metadata":{}},{"cell_type":"code","source":"def read_batch(data, visualize_data=True):\n   ent = data[np.random.randint(len(data))]\n   Img = cv2.imread(ent[\"image\"])[..., ::-1]\n   ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)\n\n   if Img is None or ann_map is None:\n       print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n       return None, None, None, 0\n\n   r = np.min([1024 / Img.shape[1], 1024 / Img.shape[0]])\n   Img = cv2.resize(Img, (int(Img.shape[1] * r), int(Img.shape[0] * r)))\n   ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)),\n                        interpolation=cv2.INTER_NEAREST)\n\n   binary_mask = np.zeros_like(ann_map, dtype=np.uint8)\n   points = []\n   inds = np.unique(ann_map)[1:]\n   for ind in inds:\n       mask = (ann_map == ind).astype(np.uint8)\n       binary_mask = np.maximum(binary_mask, mask)\n\n   eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n   coords = np.argwhere(eroded_mask > 0)\n   if len(coords) > 0:\n       for _ in inds:\n           yx = np.array(coords[np.random.randint(len(coords))])\n           points.append([yx[1], yx[0]])\n   points = np.array(points)\n\n   if visualize_data:\n       plt.figure(figsize=(15, 5))\n       plt.subplot(1, 3, 1)\n       plt.title('Original Image')\n       plt.imshow(Img)\n       plt.axis('off')\n\n       plt.subplot(1, 3, 2)\n       plt.title('Binarized Mask')\n       plt.imshow(binary_mask, cmap='gray')\n       plt.axis('off')\n\n       plt.subplot(1, 3, 3)\n       plt.title('Binarized Mask with Points')\n       plt.imshow(binary_mask, cmap='gray')\n       colors = list(mcolors.TABLEAU_COLORS.values())\n       for i, point in enumerate(points):\n           plt.scatter(point[0], point[1], c=colors[i % len(colors)], s=25)\n       plt.axis('off')\n\n       plt.tight_layout()\n       plt.show()\n\n   binary_mask = np.expand_dims(binary_mask, axis=-1)\n   binary_mask = binary_mask.transpose((2, 0, 1))\n   points = np.expand_dims(points, axis=1)\n   return Img, binary_mask, points, len(inds)\n\nImg1, masks1, points1, num_masks = read_batch(train_data, visualize_data=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:00.161557Z","iopub.execute_input":"2025-04-18T15:56:00.161846Z","iopub.status.idle":"2025-04-18T15:56:00.806469Z","shell.execute_reply.started":"2025-04-18T15:56:00.161826Z","shell.execute_reply":"2025-04-18T15:56:00.805716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sam2_checkpoint = \"/kaggle/input/sample/sam2_hiera_tiny.pt\"\nmodel_cfg = \"sam2_hiera_t.yaml\"\n\nsam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\npredictor = SAM2ImagePredictor(sam2_model)\n\npredictor.model.sam_mask_decoder.train(True)\npredictor.model.sam_prompt_encoder.train(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:12.287801Z","iopub.execute_input":"2025-04-18T15:56:12.288188Z","iopub.status.idle":"2025-04-18T15:56:13.051791Z","shell.execute_reply.started":"2025-04-18T15:56:12.288128Z","shell.execute_reply":"2025-04-18T15:56:13.050763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = torch.amp.GradScaler()\nNO_OF_STEPS = 3000\nFINE_TUNED_MODEL_NAME = \"SAM2_FT_Kidney\"\n\noptimizer = torch.optim.AdamW(params=predictor.model.parameters(),\n                              lr=0.0005,\n                              weight_decay=1e-4)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.6)\naccumulation_steps = 8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:15.484598Z","iopub.execute_input":"2025-04-18T15:56:15.484898Z","iopub.status.idle":"2025-04-18T15:56:15.495443Z","shell.execute_reply.started":"2025-04-18T15:56:15.484875Z","shell.execute_reply":"2025-04-18T15:56:15.49463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_batch(data, visualize_data=True):\n   ent = data[np.random.randint(len(data))]\n   Img = cv2.imread(ent[\"image\"])[..., ::-1]\n   ann_map = cv2.imread(ent[\"annotation\"], cv2.IMREAD_GRAYSCALE)\n\n   if Img is None or ann_map is None:\n       print(f\"Error: Could not read image or mask from path {ent['image']} or {ent['annotation']}\")\n       return None, None, None, 0\n\n   r = np.min([1024 / Img.shape[1], 1024 / Img.shape[0]])\n   Img = cv2.resize(Img, (int(Img.shape[1] * r), int(Img.shape[0] * r)))\n   ann_map = cv2.resize(ann_map, (int(ann_map.shape[1] * r), int(ann_map.shape[0] * r)),\n                        interpolation=cv2.INTER_NEAREST)\n\n   binary_mask = np.zeros_like(ann_map, dtype=np.uint8)\n   points = []\n   inds = np.unique(ann_map)[1:]\n   for ind in inds:\n       mask = (ann_map == ind).astype(np.uint8)\n       binary_mask = np.maximum(binary_mask, mask)\n\n   eroded_mask = cv2.erode(binary_mask, np.ones((5, 5), np.uint8), iterations=1)\n   coords = np.argwhere(eroded_mask > 0)\n   if len(coords) > 0:\n       for _ in inds:\n           yx = np.array(coords[np.random.randint(len(coords))])\n           points.append([yx[1], yx[0]])\n   points = np.array(points)\n\n   if visualize_data:\n       plt.figure(figsize=(15, 5))\n       plt.subplot(1, 3, 1)\n       plt.title('Original Image')\n       plt.imshow(Img)\n       plt.axis('off')\n\n       plt.subplot(1, 3, 2)\n       plt.title('Binarized Mask')\n       plt.imshow(binary_mask, cmap='gray')\n       plt.axis('off')\n\n       plt.subplot(1, 3, 3)\n       plt.title('Binarized Mask with Points')\n       plt.imshow(binary_mask, cmap='gray')\n       colors = list(mcolors.TABLEAU_COLORS.values())\n       for i, point in enumerate(points):\n           plt.scatter(point[0], point[1], c=colors[i % len(colors)], s=25)\n       plt.axis('off')\n\n       plt.tight_layout()\n       plt.show()\n\n   binary_mask = np.expand_dims(binary_mask, axis=-1)\n   binary_mask = binary_mask.transpose((2, 0, 1))\n   points = np.expand_dims(points, axis=1)\n   return Img, binary_mask, points, len(inds)\n\nImg1, masks1, points1, num_masks = read_batch(train_data, visualize_data=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:18.328087Z","iopub.execute_input":"2025-04-18T15:56:18.328438Z","iopub.status.idle":"2025-04-18T15:56:18.941202Z","shell.execute_reply.started":"2025-04-18T15:56:18.328412Z","shell.execute_reply":"2025-04-18T15:56:18.940189Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **SGD**","metadata":{}},{"cell_type":"code","source":"# def train(predictor, train_data, step, mean_iou):\n#     global max_mean_iou_in_interval  # Store max IoU across interval\n    \n#     with torch.amp.autocast(device_type='cuda'):\n#         image, mask, input_point, num_masks = read_batch(train_data, visualize_data=False)\n\n#         if image is None or mask is None or num_masks == 0:\n#             return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n#         input_label = np.ones((num_masks, 1))\n\n#         # Ensure input_point has at least one valid point\n#         if input_point is None or input_point.size == 0:\n#             print(f\"⚠ Step {step}: Skipping due to empty input_point\")\n#             return max_mean_iou_in_interval  \n\n#         # Ensure correct shape (N,1,2)\n#         if input_point.ndim == 2 and input_point.shape[1] == 2:\n#             input_point = np.expand_dims(input_point, axis=1)\n\n#         predictor.set_image(image)\n#         mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n#             input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n#         )\n\n#         sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n#             points=(unnorm_coords, labels), boxes=None, masks=None\n#         )\n\n#         batched_mode = unnorm_coords.shape[0] > 1\n#         high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n#         low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n#             image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n#             image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n#             sparse_prompt_embeddings=sparse_embeddings,\n#             dense_prompt_embeddings=dense_embeddings,\n#             multimask_output=True,\n#             repeat_image=batched_mode,\n#             high_res_features=high_res_features,\n#         )\n\n#         prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n\n#         gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n#         prd_mask = torch.sigmoid(prd_masks[:, 0])\n\n#         seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n\n#         inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n#         iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n\n#         score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n#         loss = seg_loss + score_loss * 0.05\n\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n#         scheduler.step()  # <-- Updated: Adjust learning rate after optimizer step\n\n#         # Update mean IoU\n#         mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n\n#         # Track max mean IoU in the interval\n#         if step % (NO_OF_STEPS / 10) == 1:  # Start of interval\n#             max_mean_iou_in_interval = mean_iou  # Reset at interval start\n\n#         max_mean_iou_in_interval = max(max_mean_iou_in_interval, mean_iou)  # Update max IoU\n        \n#         # Save logs for visualization\n#         if step % (NO_OF_STEPS / 20) == 1 or step == NO_OF_STEPS:\n#             train_logs[\"step\"].append(step)\n#             train_logs[\"loss\"].append(seg_loss.item())\n#             train_logs[\"iou\"].append(mean_iou)\n#             train_logs[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n\n#         if step % (NO_OF_STEPS / 20) == 0:\n#             current_lr = optimizer.param_groups[0][\"lr\"]\n#             print(f\"Step {step}: LR = {current_lr:.6f}, IoU = {mean_iou:.6f}, Loss = {seg_loss:.6f}\")\n\n#     return max_mean_iou_in_interval  # Return the maximum IoU in the interval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T21:52:35.197695Z","iopub.execute_input":"2025-02-17T21:52:35.19804Z","iopub.status.idle":"2025-02-17T21:52:35.20978Z","shell.execute_reply.started":"2025-02-17T21:52:35.19801Z","shell.execute_reply":"2025-02-17T21:52:35.208683Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def validate(predictor, test_data, step, mean_iou, optimizer, scheduler):\n#     global max_mean_iou_in_interval  # Store max IoU across interval\n    \n#     predictor.model.eval()\n#     with torch.amp.autocast(device_type='cuda'):\n#         with torch.no_grad():\n#             image, mask, input_point, num_masks = read_batch(test_data, visualize_data=False)\n\n#             if image is None or mask is None or num_masks == 0:\n#                 print(f\"⚠ Step {step}: Skipping due to missing or empty test data\")\n#                 return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n#             input_label = np.ones((num_masks, 1))\n\n#             if input_point is None or input_point.size == 0:\n#                 print(f\"⚠ Step {step}: Skipping due to empty input_point\")\n#                 return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n#             if input_point.ndim == 2 and input_point.shape[1] == 2:\n#                 input_point = np.expand_dims(input_point, axis=1)\n\n#             predictor.set_image(image)\n#             mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n#                 input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n#             )\n\n#             sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n#                 points=(unnorm_coords, labels), boxes=None, masks=None\n#             )\n\n#             batched_mode = unnorm_coords.shape[0] > 1\n#             high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n#             low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n#                 image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n#                 image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n#                 sparse_prompt_embeddings=sparse_embeddings,\n#                 dense_prompt_embeddings=dense_embeddings,\n#                 multimask_output=True,\n#                 repeat_image=batched_mode,\n#                 high_res_features=high_res_features,\n#             )\n\n#             prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n\n#             gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n#             prd_mask = torch.sigmoid(prd_masks[:, 0])\n\n#             seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6)\n#                         - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n\n#             inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n#             iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n\n#             if step % (NO_OF_STEPS / 2) == 0:\n#                 FINE_TUNED_MODEL = FINE_TUNED_MODEL_NAME + \"_\" + str(step) + \".pt\"\n#                 torch.save(predictor.model.state_dict(), FINE_TUNED_MODEL)\n\n#             mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n\n#             # Track max mean IoU in the interval\n#             if step % (NO_OF_STEPS / 10) == 1:  # Start of interval\n#                 max_mean_iou_in_interval = mean_iou  # Reset at interval start\n\n#             max_mean_iou_in_interval = max(max_mean_iou_in_interval, mean_iou)  # Update max IoU\n            \n#             writer.add_scalar(\"Loss/Validation\", seg_loss.item(), step)\n#             writer.add_scalar(\"IoU/Validation\", mean_iou, step)\n\n#             if step % (NO_OF_STEPS / 10) == 1 or step == NO_OF_STEPS:\n#                 valid_logs[\"step\"].append(step)\n#                 valid_logs[\"loss\"].append(seg_loss.item())\n#                 valid_logs[\"iou\"].append(mean_iou)\n\n#             if step == NO_OF_STEPS:\n#                 valid_logs[\"step\"].append(step)\n#                 valid_logs[\"loss\"].append(seg_loss.item())\n#                 valid_logs[\"iou\"].append(mean_iou)\n\n#             if step % (NO_OF_STEPS / 20) == 0:\n#                 print(f\"Step {step}: Validation IoU = {mean_iou:.6f}, Validation Loss = {seg_loss:.6f}\")\n\n#             scheduler.step()  # Update the learning rate using the scheduler\n#             current_lr = optimizer.param_groups[0][\"lr\"]\n#             writer.add_scalar(\"LR/Validation\", current_lr, step)\n\n#     return max_mean_iou_in_interval  # Return the maximum IoU in the interval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T21:55:14.716436Z","iopub.execute_input":"2025-02-17T21:55:14.716817Z","iopub.status.idle":"2025-02-17T21:55:14.728817Z","shell.execute_reply.started":"2025-02-17T21:55:14.716791Z","shell.execute_reply":"2025-02-17T21:55:14.727914Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **AdamW**","metadata":{}},{"cell_type":"code","source":"def train(predictor, train_data, step, mean_iou):\n    global max_mean_iou_in_interval  # Store max IoU across interval\n    \n    with torch.amp.autocast(device_type='cuda'):\n        image, mask, input_point, num_masks = read_batch(train_data, visualize_data=False)\n\n        if image is None or mask is None or num_masks == 0:\n            return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n        input_label = np.ones((num_masks, 1))\n\n        # Ensure input_point has at least one valid point\n        if input_point is None or input_point.size == 0:\n            print(f\"⚠ Step {step}: Skipping due to empty input_point\")\n            return max_mean_iou_in_interval  \n\n        # Ensure correct shape (N,1,2)\n        if input_point.ndim == 2 and input_point.shape[1] == 2:\n            input_point = np.expand_dims(input_point, axis=1)\n\n        predictor.set_image(image)\n        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n            input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n        )\n\n        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n            points=(unnorm_coords, labels), boxes=None, masks=None\n        )\n\n        batched_mode = unnorm_coords.shape[0] > 1\n        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n            image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n            sparse_prompt_embeddings=sparse_embeddings,\n            dense_prompt_embeddings=dense_embeddings,\n            multimask_output=True,\n            repeat_image=batched_mode,\n            high_res_features=high_res_features,\n        )\n\n        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n\n        gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n        prd_mask = torch.sigmoid(prd_masks[:, 0])\n\n        seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n\n        inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n        iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n\n        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n        loss = seg_loss + score_loss * 0.05\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        # Update mean IoU\n        mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n\n        # Track max mean IoU in the interval\n        if step % (NO_OF_STEPS / 10) == 1:  # Start of interval\n            max_mean_iou_in_interval = mean_iou  # Reset at interval start\n\n        max_mean_iou_in_interval = max(max_mean_iou_in_interval, mean_iou)  # Update max IoU\n        \n        # Save logs for visualization\n        if step % (NO_OF_STEPS / 20) == 1 or step == NO_OF_STEPS:\n            train_logs[\"step\"].append(step)\n            train_logs[\"loss\"].append(seg_loss.item())\n            train_logs[\"iou\"].append(mean_iou)\n            train_logs[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n\n        if step % (NO_OF_STEPS / 20) == 0:\n            current_lr = optimizer.param_groups[0][\"lr\"]\n            print(f\"Step {step}: LR = {current_lr:.6f}, IoU = {mean_iou:.6f}, Loss = {seg_loss:.6f}\")\n\n    return max_mean_iou_in_interval  # Return the maximum IoU in the interval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:27.854906Z","iopub.execute_input":"2025-04-18T15:56:27.855297Z","iopub.status.idle":"2025-04-18T15:56:27.868894Z","shell.execute_reply.started":"2025-04-18T15:56:27.855262Z","shell.execute_reply":"2025-04-18T15:56:27.867846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def validate(predictor, test_data, step, mean_iou):\n    global max_mean_iou_in_interval  # Store max IoU across interval\n    \n    predictor.model.eval()\n    with torch.amp.autocast(device_type='cuda'):\n        with torch.no_grad():\n            image, mask, input_point, num_masks = read_batch(test_data, visualize_data=False)\n\n            if image is None or mask is None or num_masks == 0:\n                print(f\"⚠ Step {step}: Skipping due to missing or empty test data\")\n                return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n            input_label = np.ones((num_masks, 1))\n\n            if input_point is None or input_point.size == 0:\n                print(f\"⚠ Step {step}: Skipping due to empty input_point\")\n                return max_mean_iou_in_interval  # Return max IoU in the interval  \n\n            if input_point.ndim == 2 and input_point.shape[1] == 2:\n                input_point = np.expand_dims(input_point, axis=1)\n\n            predictor.set_image(image)\n            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n                input_point, input_label, box=None, mask_logits=None, normalize_coords=True\n            )\n\n            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n                points=(unnorm_coords, labels), boxes=None, masks=None\n            )\n\n            batched_mode = unnorm_coords.shape[0] > 1\n            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n                image_embeddings=predictor._features[\"image_embed\"][-1].unsqueeze(0),\n                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n                sparse_prompt_embeddings=sparse_embeddings,\n                dense_prompt_embeddings=dense_embeddings,\n                multimask_output=True,\n                repeat_image=batched_mode,\n                high_res_features=high_res_features,\n            )\n\n            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n\n            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n            prd_mask = torch.sigmoid(prd_masks[:, 0])\n\n            seg_loss = (-gt_mask * torch.log(prd_mask + 1e-6)\n                        - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-6)).mean()\n\n            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n            iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n\n            if step % (NO_OF_STEPS / 2) == 0:\n                FINE_TUNED_MODEL = FINE_TUNED_MODEL_NAME + \"_\" + str(step) + \".pt\"\n                torch.save(predictor.model.state_dict(), FINE_TUNED_MODEL)\n\n            mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n\n            # Track max mean IoU in the interval\n            if step % (NO_OF_STEPS / 10) == 1:  # Start of interval\n                max_mean_iou_in_interval = mean_iou  # Reset at interval start\n\n            # max_mean_iou_in_interval = mean_iou  # Reset at interval start\n\n            max_mean_iou_in_interval = max(max_mean_iou_in_interval, mean_iou)  # Update max IoU\n            \n            writer.add_scalar(\"Loss/Validation\", seg_loss.item(), step)\n            writer.add_scalar(\"IoU/Validation\", mean_iou, step)\n\n            if step % (NO_OF_STEPS / 10) == 1 or step == NO_OF_STEPS:\n                valid_logs[\"step\"].append(step)\n                valid_logs[\"loss\"].append(seg_loss.item())\n                valid_logs[\"iou\"].append(mean_iou)\n\n            # valid_logs[\"step\"].append(step)\n            # valid_logs[\"loss\"].append(seg_loss.item())\n            # valid_logs[\"iou\"].append(mean_iou)\n\n            if step == NO_OF_STEPS:\n                valid_logs[\"step\"].append(step)\n                valid_logs[\"loss\"].append(seg_loss.item())\n                valid_logs[\"iou\"].append(mean_iou)\n\n            if step % (NO_OF_STEPS / 20) == 0:\n                print(f\"Step {step}: Validation IoU = {mean_iou:.6f}, Validation Loss = {seg_loss:.6f}\")\n\n    return max_mean_iou_in_interval  # Return the maximum IoU in the interval\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:30.494321Z","iopub.execute_input":"2025-04-18T15:56:30.494663Z","iopub.status.idle":"2025-04-18T15:56:30.506348Z","shell.execute_reply.started":"2025-04-18T15:56:30.494633Z","shell.execute_reply":"2025-04-18T15:56:30.50543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nimport pandas as pd\n\n# Create a directory for logs and graphs\nlog_dir = \"/kaggle/working/logs\"\nwriter = SummaryWriter(log_dir=log_dir)\n\n# Store values for plotting manually\ntrain_logs = {\"step\": [], \"loss\": [], \"iou\": [], \"lr\": []}\nvalid_logs = {\"step\": [], \"loss\": [], \"iou\": []}\n\n\ntrain_mean_iou = 0\nvalid_mean_iou = 0\n\nfor step in range(1, NO_OF_STEPS + 1):\n    train_mean_iou = train(predictor, train_data, step, train_mean_iou)\n    valid_mean_iou = validate(predictor, test_data, step, valid_mean_iou)\n\nwriter.close()\n\n# Save logs as CSV files\npd.DataFrame(train_logs).to_csv(\"/kaggle/working/train_logs.csv\", index=False)\npd.DataFrame(valid_logs).to_csv(\"/kaggle/working/valid_logs.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:56:58.68567Z","iopub.execute_input":"2025-04-18T15:56:58.685977Z","iopub.status.idle":"2025-04-18T16:09:59.447031Z","shell.execute_reply.started":"2025-04-18T15:56:58.685954Z","shell.execute_reply":"2025-04-18T16:09:59.446241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load logs\ntrain_df = pd.read_csv(\"/kaggle/working/train_logs.csv\")\nvalid_df = pd.read_csv(\"/kaggle/working/valid_logs.csv\")\n\n# Set save path\nsave_path = \"/kaggle/working/\"\n\n# Plot Loss\nplt.figure(figsize=(10,5))\nplt.plot(train_df[\"step\"], train_df[\"loss\"], label=\"Train Loss\")\nplt.plot(valid_df[\"step\"], valid_df[\"loss\"], label=\"Validation Loss\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"Loss\")\nplt.ylim(0, 0.1)\nplt.legend()\nplt.title(\"Loss Curve\")\nplt.savefig(save_path + \"loss_curve.png\")  # Save the image\nplt.show()\n\n# Plot IoU\nplt.figure(figsize=(10,5))\nplt.plot(train_df[\"step\"], train_df[\"iou\"], label=\"Train IoU\")\nplt.plot(valid_df[\"step\"], valid_df[\"iou\"], label=\"Validation IoU\")\nplt.xlabel(\"Steps\")\nplt.ylabel(\"IoU\")\nplt.legend()\nplt.title(\"IoU Curve\")\nplt.savefig(save_path + \"iou_curve.png\")  # Save the image\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:11:50.919113Z","iopub.execute_input":"2025-04-18T16:11:50.919512Z","iopub.status.idle":"2025-04-18T16:11:51.483116Z","shell.execute_reply.started":"2025-04-18T16:11:50.919485Z","shell.execute_reply":"2025-04-18T16:11:51.482192Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to read and resize image & mask\ndef read_image(image_path, mask_path):\n    img = cv2.imread(image_path)\n    mask = cv2.imread(mask_path, 0)\n    \n    if img is None or mask is None:\n        raise FileNotFoundError(f\"Error reading image/mask at {image_path} or {mask_path}\")\n    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    r = min(1024 / img.shape[1], 1024 / img.shape[0])\n    img = cv2.resize(img, (int(img.shape[1] * r), int(img.shape[0] * r)))\n    mask = cv2.resize(mask, (int(mask.shape[1] * r), int(mask.shape[0] * r)), interpolation=cv2.INTER_NEAREST)\n    \n    return img, mask\n\n# Function to sample points inside the input mask\ndef get_points(mask, num_points=30):\n    coords = np.argwhere(mask > 0)\n    if len(coords) == 0:\n        raise ValueError(\"No valid points found in the mask.\")\n    return np.array([[coords[np.random.randint(len(coords))][::-1]] for _ in range(num_points)])\n\n# Load the fine-tuned model\nFINE_TUNED_MODEL_WEIGHTS = \"/kaggle/working/segment-anything-2/SAM2_FT_Kidney_3000.pt\"\nif not os.path.exists(FINE_TUNED_MODEL_WEIGHTS):\n    raise FileNotFoundError(f\"Model weights not found at {FINE_TUNED_MODEL_WEIGHTS}\")\n\nsam2_checkpoint = \"/kaggle/input/sample/sam2_hiera_tiny.pt\"\nmodel_cfg = \"sam2_hiera_t.yaml\"\n\nsam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\npredictor = SAM2ImagePredictor(sam2_model)\npredictor.model.load_state_dict(torch.load(FINE_TUNED_MODEL_WEIGHTS, map_location=\"cuda\"))\n\n# Randomly select a test image\nselected_entry = random.choice(test_data)\nimage_path, mask_path = selected_entry['image'], selected_entry['annotation']\nprint(f\"Selected Image: {image_path}\\nMask Path: {mask_path}\")\n\n# Load the image and mask\nimage, target_mask = read_image(image_path, mask_path)\n\n# Generate random points for input\ninput_points = get_points(target_mask, num_points=30)\n\n# Perform inference\nwith torch.no_grad():\n    predictor.set_image(image)\n    masks, scores, logits = predictor.predict(\n        point_coords=input_points,\n        point_labels=np.ones([input_points.shape[0], 1])\n    )\n\n# Process the predicted masks\nnp_masks = np.array(masks[:, 0])\nnp_scores = scores[:, 0]\nsorted_masks = np_masks[np.argsort(np_scores)][::-1]\n\n# Initialize segmentation map\nseg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\noccupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n\nfor i, mask in enumerate(sorted_masks):\n    if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n        continue\n    mask_bool = mask.astype(bool)\n    mask_bool[occupancy_mask] = False\n    seg_map[mask_bool] = i + 1\n    occupancy_mask[mask_bool] = True\n\n# Visualization\nplt.figure(figsize=(18, 6))\nplt.subplot(1, 3, 1)\nplt.title('Test Image')\nplt.imshow(image)\nplt.axis('off')\n\nplt.subplot(1, 3, 2)\nplt.title('Ground Truth Mask')\nplt.imshow(target_mask, cmap='gray')\nplt.axis('off')\n\nplt.subplot(1, 3, 3)\nplt.title('Predicted Segmentation Map')\nplt.imshow(seg_map, cmap='gray')\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:11:56.36342Z","iopub.execute_input":"2025-04-18T16:11:56.363745Z","iopub.status.idle":"2025-04-18T16:11:58.690708Z","shell.execute_reply.started":"2025-04-18T16:11:56.36372Z","shell.execute_reply":"2025-04-18T16:11:58.68979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\n\ndef test_model_on_sample(data_sample, predictor, num_points=30):\n    total_iou = 0.0\n    valid_samples = 0\n\n    for entry in data_sample:\n        image_path, mask_path = entry['image'], entry['annotation']\n        # print(f\"Testing: {os.path.basename(image_path)}\")\n\n        # Load image and mask\n        image, target_mask = read_image(image_path, mask_path)\n\n        # Skip if mask is empty\n        try:\n            input_points = get_points(target_mask, num_points=num_points)\n        except ValueError:\n            print(\"Skipped (empty mask)\")\n            continue\n\n        # Predict\n        with torch.no_grad():\n            predictor.set_image(image)\n            masks, scores, logits = predictor.predict(\n                point_coords=input_points,\n                point_labels=np.ones([input_points.shape[0], 1])\n            )\n\n        # Process predicted masks\n        np_masks = np.array(masks[:, 0])\n        np_scores = scores[:, 0]\n        sorted_masks = np_masks[np.argsort(np_scores)][::-1]\n\n        seg_map = np.zeros_like(sorted_masks[0], dtype=np.uint8)\n        occupancy_mask = np.zeros_like(sorted_masks[0], dtype=bool)\n\n        for i, mask in enumerate(sorted_masks):\n            if (mask * occupancy_mask).sum() / mask.sum() > 0.15:\n                continue\n            mask_bool = mask.astype(bool)\n            mask_bool[occupancy_mask] = False\n            seg_map[mask_bool] = 1  # For binary IoU\n            occupancy_mask[mask_bool] = True\n\n        # Resize target_mask to match seg_map if needed\n        if seg_map.shape != target_mask.shape:\n            target_mask = cv2.resize(target_mask, (seg_map.shape[1], seg_map.shape[0]), interpolation=cv2.INTER_NEAREST)\n\n        # Binarize the target mask (assumes mask values > 0 are foreground)\n        target_mask_bin = (target_mask > 0).astype(np.uint8)\n\n        # Flatten both masks to compute IoU\n        iou = jaccard_score(target_mask_bin.flatten(), seg_map.flatten(), zero_division=0)\n        total_iou += iou\n        valid_samples += 1\n\n    # Report average IoU\n    if valid_samples == 0:\n        print(\"No valid samples to evaluate IoU.\")\n    else:\n        avg_iou = total_iou / valid_samples\n        print(f\"\\n✅ Average IoU over {valid_samples} samples: {avg_iou:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:13:39.764024Z","iopub.execute_input":"2025-04-18T16:13:39.764427Z","iopub.status.idle":"2025-04-18T16:13:39.773903Z","shell.execute_reply.started":"2025-04-18T16:13:39.7644Z","shell.execute_reply":"2025-04-18T16:13:39.772797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_model_on_sample(data_sample, predictor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T16:22:47.063002Z","iopub.execute_input":"2025-04-18T16:22:47.063349Z"}},"outputs":[],"execution_count":null}]}